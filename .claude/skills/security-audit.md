# Security Audit

Write a security audit of this repo to `docs/security-audit.md`.

**Audience:** Security professionals and security-conscious users evaluating whether to trust this software. They should be able to follow this document, run every command, and arrive at their own conclusions. The document is a guide to verifying, not a set of claims to believe.

**Disclosure:** This document is AI-assisted. State this clearly at the top. The right framing: this audit was generated by AI to provide a structured, reproducible evaluation — every finding is backed by a command the reader runs themselves. The AI's role is directing attention to the right places; the reader's terminal is the source of truth.

**Tooling:** Go beyond grep. Use real security analysis tools that can be installed via nix. For each tool, provide the nix install command (e.g. `nix shell nixpkgs#gosec`) so anyone can reproduce without polluting their system. Good candidates:
- `govulncheck` — Go's official vulnerability database scanner
- `gosec` — Go security-focused static analysis
- `syft` + `grype` — SBOM generation and vulnerability scanning for dependencies
- `go vet`, `go mod graph`, `go mod verify` — standard Go toolchain checks
- Whatever else makes sense — if a tool exists that would give the reader real signal, use it

For each tool, show the exact command, explain briefly what it checks, and let the output speak. Don't editorialize the results — the reader will interpret them.

**Structure the audit around two questions:**

1. **Is this software safe to install and run?** No telemetry, no network calls, no phoning home, no unexpected dependencies, no known vulnerabilities in the dependency tree. This is where tooling shines — `govulncheck`, `syft`/`grype`, dependency graph analysis, WASM import inspection.

2. **Is this software secure for its purpose?** Does the Shamir/age composition hold? Are there information leaks? This is where tools reach their limit. For these sections, don't pretend a grep proves anything — instead, **point the reader to the exact code paths they need to read**, explain what the code should be doing and what to watch for, and provide enough context that a reviewer can form their own judgment in minutes rather than hours. The goal is to make it easy for someone with time and expertise to confidently say "I've reviewed this."

**Include a threat model section.** Define adversaries and scenarios:
- An attacker who obtains fewer than threshold shares
- An attacker who compromises a single friend's bundle
- An attacker with access to the creator's machine after sealing
- A malicious or compromised dependency
- A friend who acts alone trying to recover the secret

For each, explain what the design promises and point to the code that enforces it.

**Deep-dive areas** (point to specific files and functions, explain what the reader should verify):
- Passphrase lifecycle: generation, memory handling, whether it's zeroed after use, error paths that might log or leak it
- Share format: do PEM headers or bundle metadata leak information that weakens the below-threshold guarantee?
- WASM/JS boundary: is data handled correctly between Go and JavaScript? What functions are exposed?
- Tar extraction (both CLI and browser paths): zip-slip, symlink traversal, size limits
- Threshold validation: is the threshold enforced at both creation and recovery?
- Dependency surface: full dependency tree, which deps touch sensitive data, which have had past CVEs
- Ongoing maintenance: note that Dependabot is enabled on this repo for automated dependency vulnerability alerts and PRs — this is relevant context for the dependency story (point-in-time scan + continuous monitoring)

**Confidence levels:** For each finding, be explicit:
- "Tool output" — the reader runs it and sees the result themselves
- "Code pointer" — here's where to look and what to look for; the reader must read and judge
- "Structural observation" — an architectural property that follows from how the code is organized

Don't present automated scans as proof of security properties. Present them as evidence. And when the real assurance comes from reading code, say so and make that reading as easy as possible.

**This is a point-in-time artifact.** Record the commit hash being audited at the top of the document. When referencing code, link to the exact lines on GitHub using the commit hash so links are permanent — e.g. `https://github.com/eljojo/rememory/blob/<commit>/path/to/file.go#L12-L17`. This makes the audit a stable, citable artifact: readers see exactly what was reviewed, and links don't drift as the codebase evolves. Use `git rev-parse HEAD` to get the current commit hash.

**Include a "where a professional reviewer should focus" section.** If someone is hiring a security consultant, which files and code paths deserve the deepest scrutiny? Rank them by risk and explain why. This is the most valuable part of the document — it turns hours of orientation into minutes.

**Tone:** Technically precise, honest about limits, not reassuring. The goal is to help readers make their own trust decision, not to sell them on safety.
